{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "#display results\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "plt.style.use('grayscale')\n",
    "              \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[cs231n](http://cs231n.stanford.edu/syllabus.html) : Lesson 1-2\n",
    "\n",
    "[Udacity. Computational Photography](https://www.udacity.com/course/computational-photography--ud955)\n",
    "\n",
    "[Udacity. Introduction to Computer Vision](https://www.udacity.com/course/introduction-to-computer-vision--ud810)\n",
    "\n",
    "[PyImageSearch](https://www.pyimagesearch.com/)\n",
    "\n",
    "[LearnOpenCV](https://www.learnopencv.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Image Processing Important? \n",
    "[Source](https://electrek.co/2018/06/11/tesla-ai-director-insights-autopilot-computer-vision-neural-net/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1](images/amount_of_sleep.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](images/dataset-size-accuracy.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic CV vs Deep Learning CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classic CV : less data, more expertise\n",
    "- Deep Learning CV: more data, less expertise\n",
    "\n",
    "**Do both**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make plots bigger\n",
    "scale = 2\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] *= scale\n",
    "fig_size[1] *= scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    \"\"\"\n",
    "    Loads image from file \n",
    "    \n",
    "    Arguments:\n",
    "        filename: str\n",
    "        \n",
    "    Returns:\n",
    "        result: np.ndarray\n",
    "    \"\"\"\n",
    "    assert os.path.exists(filename)\n",
    "    return cv2.imread(filename)\n",
    "\n",
    "def to_rgb(image):\n",
    "    \"\"\"\n",
    "    Converts BGR to RGB colorspace\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def to_gray(image):\n",
    "    \"\"\"\n",
    "    Converts BGR to GRAY colorspace\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def draw_image(source, image, x, y, opacity=1.0):\n",
    "\n",
    "    h,w  = image.shape[:2]    \n",
    "    \n",
    "    max_x, max_y = x + w, y + h    \n",
    "    \n",
    "    alpha = None\n",
    "    if len(image.shape) < 3 or image.shape[2] < 4:\n",
    "        if (len(image.shape) == 2):\n",
    "            alpha = np.float32(image > 0)\n",
    "        else:\n",
    "            alpha = np.float32(image[:, :, 0] > 0)\n",
    "    else:\n",
    "        alpha = image[:, :, 3] / 255.0 \n",
    "\n",
    "    alpha = alpha * min(1.0, max(opacity, 0.0))  \n",
    "\n",
    "    for c in range(0,3):\n",
    "        color = image[:, :, c] * (alpha)\n",
    "        beta = source[y:max_y, x:max_x, c] * (1.0 - alpha)\n",
    "        source[y:max_y, x:max_x, c] = color + beta\n",
    "    return source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_side_by_side(left, right):\n",
    "    f, axarr = plt.subplots(1, 2, sharex=True)\n",
    "    axarr[0].imshow(left)\n",
    "    axarr[1].imshow(right)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_side_by_side_many_vertical(images):\n",
    "    # f, axarr = plt.subplots(2, len(images) // 2, sharex=True)\n",
    "    for i, image in enumerate(images):\n",
    "        plt.imshow(image)\n",
    "        # axarr[i].imshow(image)\n",
    "        plt.show()\n",
    "        \n",
    "def plot_side_by_side_many_horizontal(images):\n",
    "    f, axarr = plt.subplots(1, len(images), sharex=True)\n",
    "    for i, image in enumerate(images):\n",
    "        axarr[i].imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Processing Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FILENAME = \"images/elephant.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = load_image(FILENAME)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(image.shape)  # h x w x c (HWC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.expand_dims(image, 0).shape)  # NHWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(image[:3, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.min(image), np.max(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Numpy Datatypes](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(image.dtype) # uint8, float ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# uint8 -> 0..255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://www.learnopencv.com/color-spaces-in-opencv-cpp-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grayscale\n",
    "\n",
    "**Channels**: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_side_by_side_many_horizontal([image, to_gray(image)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inverse(image, max_intensity=255):\n",
    "    return max_intensity - image\n",
    "\n",
    "plot_side_by_side_many_horizontal([to_gray(image), inverse(to_gray(image))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB\n",
    "**Channels**: 3\n",
    "\n",
    "- Red\n",
    "- Green\n",
    "- Blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1](images/color_spaces/rgb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r, g, b = cv2.split(image)\n",
    "\n",
    "plot_side_by_side_many_horizontal([r, g, b ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Channels in Any Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bgr = cv2.merge([b, g, r])\n",
    "plt.imshow(bgr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGBA\n",
    "\n",
    "**Channels**: 4\n",
    "\n",
    "- Red\n",
    "- Green\n",
    "- Blue\n",
    "- Alpha (Pixel Transparency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wall = load_image(\"images/wall.jpg\")\n",
    "wall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sticker = cv2.imread(\"images/sticker.png\", -1)\n",
    "sticker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_side_by_side_many_vertical([wall, sticker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "wall_w, wall_h = wall.shape[:2][::-1]\n",
    "sticker_w, sticker_h = sticker.shape[:2][::-1]\n",
    "\n",
    "cv2.createTrackbar('x','image', 0, wall_w - sticker_w, nothing)\n",
    "cv2.createTrackbar('y','image', 0, wall_h - sticker_h, nothing)\n",
    "cv2.createTrackbar('alpha','image', 100, 100, nothing)\n",
    "\n",
    "\n",
    "try:\n",
    "    while(True):           \n",
    "        # updating HSV Thresholds\n",
    "        x, y = cv2.getTrackbarPos('x','image'), cv2.getTrackbarPos('y','image')\n",
    "        alpha = cv2.getTrackbarPos('alpha','image')\n",
    "        # Apply Mask to image\n",
    "        cv2.imshow('image', draw_image(wall.copy(), sticker, x, y, alpha / 100))           \n",
    "       \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB\n",
    "\n",
    "**Channels**: 3\n",
    "\n",
    "- L – Lightness ( Intensity ).\n",
    "- a – color component ranging from Green to Magenta.\n",
    "- b – color component ranging from Blue to Yellow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1](images/color_spaces/lab.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_side_by_side_many_horizontal(cv2.split(cv2.cvtColor(image, cv2.COLOR_BGR2LAB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YCrCb\n",
    "\n",
    "**Channels**: 3\n",
    "\n",
    "- Y – Luminance or Luma component obtained from RGB after gamma correction.\n",
    "- Cr = R – Y ( how far is the red component from Luma ).\n",
    "- Cb = B – Y ( how far is the blue component from Luma ).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1](images/color_spaces/ycrcb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_side_by_side_many_horizontal(cv2.split(cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV\n",
    "\n",
    "**Channels**: 3\n",
    "\n",
    "- H – Hue ( Dominant Wavelength ).\n",
    "- S – Saturation ( Purity / shades of the color ).\n",
    "- V – Value ( Intensity )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1](images/color_spaces/hsv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_side_by_side_many_horizontal(cv2.split(cv2.cvtColor(image, cv2.COLOR_BGR2HSV)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "cv2.createTrackbar('hl','image', 0, 255, nothing)\n",
    "cv2.createTrackbar('hh','image', 255, 255, nothing)\n",
    "cv2.createTrackbar('sl','image', 0, 255, nothing)\n",
    "cv2.createTrackbar('sh','image', 255, 255,nothing)\n",
    "cv2.createTrackbar('vl','image', 0, 255, nothing)\n",
    "cv2.createTrackbar('vh','image', 255, 255, nothing)\n",
    "\n",
    "image = load_image(\"images/nature.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "try:\n",
    "    while(True):           \n",
    "        # updating HSV Thresholds\n",
    "        lo = np.array([cv2.getTrackbarPos('hl','image'),cv2.getTrackbarPos('sl','image'),cv2.getTrackbarPos('vl','image')])\n",
    "        hi = np.array([cv2.getTrackbarPos('hh','image'),cv2.getTrackbarPos('sh','image'),cv2.getTrackbarPos('vh','image')])      \n",
    "      \n",
    "        # Remove values that are not in HSV Thresholds\n",
    "        mask = cv2.inRange(hsv, lo, hi)\n",
    "            \n",
    "        # Apply Mask to image\n",
    "        cv2.imshow('image', cv2.bitwise_and(image,image, mask=mask))           \n",
    "       \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gray = to_gray(image)\n",
    "hist, bins = np.histogram(gray.ravel(), 256,[0,256])\n",
    "\n",
    "# print(bins)\n",
    "plt.hist(gray.ravel(), 256, [0,256]);\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "1D : https://graphics.stanford.edu/courses/cs178-10/applets/convolution.html'\n",
    "\n",
    "2D : http://setosa.io/ev/image-kernels/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_identity_filter2d(kernel_size=3, intensity=1):\n",
    "    kernel = np.zeros((kernel_size, kernel_size),np.float32)\n",
    "    kernel[kernel_size // 2, kernel_size // 2] = intensity\n",
    "    return kernel\n",
    "\n",
    "kernel = get_identity_filter2d(5)\n",
    "plot_side_by_side(image, cv2.filter2D(image, -1, kernel))\n",
    "\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average/Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_average_filter2d(kernel_size):\n",
    "    return np.ones((kernel_size, kernel_size),np.float32) / kernel_size**2\n",
    "\n",
    "kernel = get_average_filter2d(9)\n",
    "plot_side_by_side(image, cv2.filter2D(image, -1, kernel))\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Median = middle point of ordered list (sort -> (n + 1) / 2)\n",
    "# for noise reduction\n",
    "\n",
    "plot_side_by_side(image, cv2.medianBlur(image, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAUG\n",
    "https://github.com/aleju/imgaug.git\n",
    "\n",
    "Examples: https://github.com/aleju/imgaug-doc/tree/1be9d560ccf794c8ee5a07f529907406433cace7/notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise Reduction with Median Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imgaug import augmenters as filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_with_salt = filters.Salt((0.1)).augment_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_side_by_side(image_with_salt, cv2.medianBlur(image_with_salt, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_shift_left_filter2d(kernel_size):\n",
    "    kernel = np.zeros((kernel_size, kernel_size),np.float32)\n",
    "    kernel[kernel_size // 2, kernel_size - 1] = 1\n",
    "    return kernel\n",
    "\n",
    "kernel = get_shift_left_filter2d(57)\n",
    "plot_side_by_side(image, cv2.filter2D(image, -1, kernel))\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_shift_right_filter2d(kernel_size):\n",
    "    kernel = np.zeros((kernel_size, kernel_size),np.float32)\n",
    "    kernel[kernel_size // 2, 0] = 1\n",
    "    return kernel\n",
    "\n",
    "kernel = get_shift_right_filter2d(57)\n",
    "plot_side_by_side(image, cv2.filter2D(image, -1, kernel))\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moon = load_image(\"images/moon.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_sharpening_filter(kernel_size):\n",
    "    # Stretched Laplacian + Initial Image\n",
    "    # Average - Identity = Sharp Boundaries\n",
    "    identity_kernel = get_identity_filter2d(kernel_size, intensity=2)\n",
    "    average_kernel = get_average_filter2d(kernel_size)\n",
    "    return identity_kernel - average_kernel\n",
    "\n",
    "kernel_size = 9\n",
    "kernel = get_sharpening_filter(kernel_size)\n",
    "\n",
    "plot_side_by_side(moon, cv2.filter2D(moon, -1, kernel))\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "increased_intensity = cv2.filter2D(moon, -1, get_identity_filter2d(kernel_size, intensity=2)) \n",
    "plot_side_by_side(moon, increased_intensity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sigma = 3\n",
    "kernel_size = 21\n",
    "window = cv2.getGaussianKernel(kernel_size, sigma)\n",
    "\n",
    "plt.plot(window)\n",
    "plt.title(r\"Gaussian window ($\\sigma$={})\".format(sigma))\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_gaussian_filter2d(kernel_size, sigma=1):\n",
    "    gaussian_filter = cv2.getGaussianKernel(kernel_size, sigma).flatten()\n",
    "    \n",
    "    gaussian_filter = gaussian_filter.reshape((len(gaussian_filter), 1)) * gaussian_filter\n",
    "    \n",
    "    gaussian_filter /= np.sum(gaussian_filter)\n",
    "    return gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel = get_gaussian_filter2d(9, 2)\n",
    "\n",
    "plot_side_by_side(image, cv2.filter2D(image, -1, kernel))\n",
    "\n",
    "plt.imshow(kernel)\n",
    "plt.show()\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel (Vertical Edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dx_filter2d():\n",
    "    return np.array([[0, 1, -1]] * 3, dtype=np.float32)\n",
    "\n",
    "def get_dx_sobel_filter2d():\n",
    "    return np.array([[1, 0, -1]] * 3, dtype=np.float32)\n",
    "\n",
    "kernel = get_dx_filter2d()\n",
    "plot_side_by_side(image, cv2.filter2D(image, -1, kernel))\n",
    "\n",
    "print(kernel)\n",
    "\n",
    "kernel[kernel == -1] = 0\n",
    "plt.imshow(kernel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel (Horizontal Edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dy_filter2d():\n",
    "    return np.array([[0, 1, -1]] * 3, dtype=np.float32).T\n",
    "\n",
    "def get_dy_sobel_filter2d():\n",
    "    return np.array([[1, 0, -1]] * 3, dtype=np.float32).T \n",
    "\n",
    "kernel = get_dy_filter2d()\n",
    "\n",
    "plot_side_by_side(image, cv2.filter2D(image, -1, kernel))\n",
    "\n",
    "print(kernel)\n",
    "\n",
    "kernel[kernel == -1] = 0\n",
    "plt.imshow(kernel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian\n",
    "Second derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dx2_filter2d():\n",
    "    # Second derivative  X\n",
    "    # f(x + 1) + f(x - 1) - 2f(x)\n",
    "\n",
    "    return np.array([\n",
    "        [0, 0, 0],\n",
    "        [1, -2, 1],\n",
    "        [0, 0, 0]\n",
    "    ])\n",
    "    \n",
    "plot_side_by_side(image, cv2.filter2D(image, -1, get_dx2_filter2d()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dy2_filter2d():\n",
    "    # Second derivative  Y\n",
    "    # f(y + 1) + f(y - 1) - 2f(y)\n",
    "\n",
    "    return np.array([\n",
    "        [0, 1, 0],\n",
    "        [0, -2, 0],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "\n",
    "plot_side_by_side(image, cv2.filter2D(image, -1, get_dy2_filter2d()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take Laplacian in Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_laplacian_filter2d():\n",
    "    return get_dx2_filter2d() + get_dy2_filter2d()\n",
    "\n",
    "kernel = get_laplacian_filter2d()\n",
    "plot_side_by_side(image, cv2.filter2D(image, -1, get_laplacian_filter2d()))\n",
    "\n",
    "plt.imshow(kernel)\n",
    "plt.show()\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_blurred_laplacian():\n",
    "    kernel = np.array([1, 2, -1], dtype=np.float32)\n",
    "    return kernel.reshape((len(kernel), 1)) * kernel\n",
    "\n",
    "kernel = get_blurred_laplacian()\n",
    "plot_side_by_side(image, cv2.filter2D(image, -1, kernel))\n",
    "\n",
    "print(kernel)\n",
    "\n",
    "plt.imshow(kernel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient (Orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "horizontal = np.array([[0, 0, 0], [255, 255, 255], [0, 0, 0]], dtype=np.uint8)\n",
    "vertical = np.array([[255, 0, 255], [255, 0, 255], [255, 0, 255]], dtype=np.uint8)\n",
    "corner = np.array([[0, 255, 255], [255, 0, 255], [255, 255, 0]], dtype=np.uint8)\n",
    "\n",
    "array = vertical\n",
    "plt.imshow(array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dx = cv2.filter2D(array, -1, get_dx_filter2d())\n",
    "dy = cv2.filter2D(array, -1, get_dy_filter2d())\n",
    "plot_side_by_side(dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gradient = np.sqrt(np.square(dx) + np.square(dy))\n",
    "gradient = (gradient/np.max(gradient) * 255).astype('uint8')\n",
    "\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dy = dy.astype('float32') + 0.0001 # avoid zero\n",
    "angle = np.ceil(np.degrees(np.arctan(dx / dy)))\n",
    "\n",
    "print(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DX\n",
    "dx = cv2.filter2D(image, -1, get_dx_filter2d())\n",
    "dy = cv2.filter2D(image, -1, get_dy_filter2d())\n",
    "\n",
    "plot_side_by_side(dx, dy)\n",
    "\n",
    "# Gradient\n",
    "gradient = np.sqrt(np.square(dx) + np.square(dy))\n",
    "gradient = (gradient/np.max(gradient) * 255).astype('uint8')\n",
    "\n",
    "# Angle\n",
    "dy = dy.astype('float32') + 0.0001 # avoid zero\n",
    "angle = np.arctan(dx / dy)\n",
    "angle = ((angle/np.max(angle)) * 255).astype('uint8')\n",
    "\n",
    "plt.imshow(gradient)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motion Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_motion_blur_filter2d(size=3):\n",
    "    # generating the kernel\n",
    "    kernel = np.zeros((size, size))\n",
    "    # kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "    kernel[int((size-1)/2), int((size-1)/2)] = 1\n",
    "    kernel[int((size-1)/2), int((size-1)/2) + size // 2] = 1\n",
    "\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "# applying the kernel to the input image\n",
    "kernel = get_motion_blur_filter2d(7)\n",
    "\n",
    "plot_side_by_side(image, cv2.filter2D(image, -1, kernel))\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integral Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example](images/integral_image.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = 4\n",
    "a = np.linspace(0, size**2, size**2, dtype=np.uint8).reshape(size, size)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "integral = cv2.integral(a)\n",
    "print(integral[1:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "integral = cv2.integral(image)\n",
    "\n",
    "plot_side_by_side(image, ((integral/np.max(integral)) * 255).astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.pyimagesearch.com/2014/03/03/charizard-explains-describe-quantify-image-using-feature-vectors/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_shift_left_filter2d(kernel_size):\n",
    "    kernel = np.zeros((kernel_size, kernel_size),np.float32)\n",
    "    kernel[kernel_size // 2, kernel_size - 1] = 1\n",
    "    return kernel\n",
    "\n",
    "kernel = get_shift_left_filter2d(3)\n",
    "shifted = cv2.filter2D(image, -1, kernel)\n",
    "plot_side_by_side(image, shifted)\n",
    "\n",
    "print(np.sum(image - image))\n",
    "print(np.sum(shifted - image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_initial, bins = np.histogram(to_gray(image).ravel(), 256,[0,256])\n",
    "hist_shifted, bins = np.histogram(to_gray(shifted).ravel(), 256,[0,256])\n",
    "print(np.sum(hist_initial - hist_shifted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.pyimagesearch.com/2014/01/27/hobbits-and-histograms-a-how-to-guide-to-building-your-first-image-search-engine-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://machinelearningmastery.com/using-opencv-python-and-template-matching-to-play-wheres-waldo/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "where_waldo = load_image(\"images/puzzle_small.jpg\")\n",
    "\n",
    "plot_side_by_side_many_vertical([where_waldo, load_image(\"images/waldo.jpg\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Examples: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_template_matching/py_template_matching.html\n",
    "template = where_waldo[570:610, 98:112, :]\n",
    "correlation_map = cv2.matchTemplate(where_waldo, waldo, cv2.TM_CCOEFF)\n",
    "plt.imshow(correlation_map)\n",
    "plt.show()\n",
    "\n",
    "# Find Britest spot of image\n",
    "# https://www.pyimagesearch.com/2014/09/29/finding-brightest-spot-image-using-python-opencv/\n",
    "\n",
    "# float, float, (int, int), (int, int)\n",
    "min_value, max_value, min_value_xy, max_value_xy = cv2.minMaxLoc(correlation_map)\n",
    "\n",
    "w, h = waldo.shape[:2][::-1]\n",
    "plt.imshow(cv2.circle(where_waldo.copy(), (max_value_xy[0] + w // 2, max_value_xy[1] + h // 2), 20, (255, 0, 0), 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG\n",
    " https://gurus.pyimagesearch.com/lesson-sample-histogram-of-oriented-gradients-and-car-logo-recognition/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Draw HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Algorithm\n",
    "- Resize\n",
    "- Calculate DX, DY\n",
    "- Calculate Gradient\n",
    "- Calculate Angles\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hog](images/hog_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "plot_side_by_side(image, hog_image_rescaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HAAR\n",
    "https://docs.opencv.org/3.4/d7/d8b/tutorial_py_face_detection.html\n",
    "\n",
    "Video Explanation: https://www.youtube.com/watch?v=x41KFOFGnUE&t=244s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Haar](images/haar.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import haar_like_feature_coord\n",
    "from skimage.feature import draw_haar_like_feature\n",
    "\n",
    "images = [np.zeros((2, 2)), np.zeros((2, 2)),\n",
    "          np.zeros((3, 3)), np.zeros((3, 3)),\n",
    "          np.zeros((2, 2))]\n",
    "\n",
    "feature_types = ['type-2-x', 'type-2-y',\n",
    "                 'type-3-x', 'type-3-y',\n",
    "                 'type-4']\n",
    "\n",
    "fig, axs = plt.subplots(3, 2)\n",
    "for ax, img, feat_t in zip(np.ravel(axs), images, feature_types):\n",
    "    coord, _ = haar_like_feature_coord(img.shape[0], img.shape[1], feat_t)\n",
    "    haar_feature = draw_haar_like_feature(img, 0, 0,\n",
    "                                          img.shape[0],\n",
    "                                          img.shape[1],\n",
    "                                          coord,\n",
    "                                          max_n_features=1,\n",
    "                                          random_state=0)\n",
    "    ax.imshow(haar_feature)\n",
    "    ax.set_title(feat_t)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig.suptitle('The different Haar-like feature descriptors')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Haar](images/haar_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand Mouse Control Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Project](https://imaginghub.com/blog/14-how-to-implement-gesture-control-on-embedded-systems)\n",
    "[Explanation](https://imaginghub.com/projects/173-implementing-gesture-control-on-raspberry-pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Google Collaboratory\n",
    "- Virtual Envoronments\n",
    "- Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_course",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
